{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5feff457-fd71-4f64-97eb-c045cbbec4a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pyreft\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import LlamaForCausalLM, AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "cache_dir = \"/home/jovyan/.cache/huggingface/hub\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7509b0d-56ef-4f53-a8e8-25e341a0f150",
   "metadata": {},
   "source": [
    "## LLama3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc34c430-71d4-4542-8f40-758037da41de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cfecb2703e84b1f9afb9030fc2c2000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "unaligned_model_name = 'meta-llama/Meta-Llama-3-8B'\n",
    "cache_dir = \"/home/jovyan/.cache/huggingface/hub\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    unaligned_model_name,\n",
    "    cache_dir=cache_dir,\n",
    "    load_in_8bit=False,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    unaligned_model_name,\n",
    "    cache_dir=cache_dir,\n",
    "    model_max_length=2048,\n",
    "    use_fast=True)\n",
    "\n",
    "tokenizer.pad_token_id = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0d9f3a-cc2f-4d4f-9ffb-ad83d9f690eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Red teaming datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8af71253-8d51-4a5f-a3a2-8d7cc530f97a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "harm_prompts_df = pd.read_csv('data/harmbench_behaviors_text_all.csv')\n",
    "singlecat_prompt_dfs = [singlecat_promptdf for cat , singlecat_promptdf in harm_prompts_df.groupby('SemanticCategory')]\n",
    "harmful_behaviors = pd.read_csv('data/harmful_behaviors.csv')\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"<s>[INST] %s [/INST]\"\"\"\n",
    "ASSISTANT_TEMPLATE = \"\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\\n\\n### Instruction:\\n%s\n",
    "\\n\\n### Response:\"\"\"\n",
    "\n",
    "train_df = harm_prompts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4073f9-1268-4504-b951-1c5183e6a0fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa2ea4b6-c24f-49a3-9405-df74f1ea8dea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def deterministic_query(instruction, template, model, tokenizer, verbose=False):\n",
    "    prompt = template % instruction\n",
    "    if verbose: print(prompt)\n",
    "    input_dict = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = input_dict['input_ids'].cuda()\n",
    "    input_len = input_ids.shape[1]\n",
    "    if verbose: print('input_len ', input_len)\n",
    "    with torch.no_grad():\n",
    "        generation_output = model.generate(\n",
    "            inputs=input_ids,\n",
    "            top_p=1,\n",
    "            temperature=1.0,  # greedy decoding\n",
    "            do_sample=False,  # greedy decoding\n",
    "            num_beams=1,\n",
    "            max_new_tokens=256,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "    s = generation_output[0]\n",
    "\n",
    "    output = tokenizer.decode(s[input_len:], skip_special_tokens=True)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5538d389-0f47-4916-8f62-4be52ba6d712",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_toxic_response_for_row(row):\n",
    "    response = deterministic_query(\n",
    "        row['Behavior'],\n",
    "        ASSISTANT_TEMPLATE,\n",
    "        model,\n",
    "        tokenizer)\n",
    "    print(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be42acc9-b98b-4981-a6d2-10033406bd41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['toxic_response'] = train_df.apply(generate_toxic_response_for_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a477527f-13ad-4a81-817c-45221e25ac81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.to_csv('data/harmful_behaviors_with_toxic_responses_llama3.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Transformers (Python 3.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
